{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "The purpose of this notebook is to explore the de-identified sample of Electronic Case Reports (eCR) that were provided by Los Angeles County (LAC) with an eye towards the following objectives:\n",
    "\n",
    "1. Determine where eCRs tend to look identical, irrespective of patient, provider, or EHR system  \n",
    "2. Determine where eCRs are most subject to change  \n",
    "3. Determine if there is a subset of variables that can be used to identify duplicate eCRs with any level of confidence  \n",
    "4. Determine how eCRs vary across different EHR systems\n",
    "5. Determine if there is a subset of variables that can be used to minimally define a \"document\" and a \"patient\"\n",
    "\n",
    "### Hypotheses\n",
    "\n",
    "*Problem Hypothesis:*\n",
    "\n",
    "- We believe Epidemiologists engage in a time-consuming, manual process of comparing eCRs to one another based on user stories that have been gathered during DIBBs user interviews.  \n",
    "- We believe STLTs, regardless of which data ingestion and/or case surveillance software they use, experience non-trivial declines in performance of those systems based on information the VIPER team received from Idaho (which uses NBS), as well as the interest in a partnership that we've seen from Chicago and Dallas (both of whom use Salesforce).\n",
    "\n",
    "*Solution Hypothesis:*\n",
    "\n",
    "- By identifying the sections of an eCR that contain pertinent information for the purposes of case investigations and the criteria by which a section of data can be determined to be duplicative or redundant, we believe epidemiologists will spend less time manually comparing eCRs, allowing them to spend more time doing the things they do best."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment Setup\n",
    "The following code imports the necessary libraries for this analysis, as well as unzips all of the data if it has not already be done. It then aggregates the list of directories, which are named the same as the zip file containing the data, which can be used later for iterating over every eCR. Lastly, it creates an eCR class that can be used to perform rudimentary queries on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from lxml import etree\n",
    "from pathlib import Path\n",
    "from xmldiff import main\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_zip_files(path):\n",
    "    for file in os.listdir(path):\n",
    "        if file.endswith(\".zip\"):\n",
    "            new_dir = os.path.join(path, file[:-4])\n",
    "            if not os.path.exists(new_dir):\n",
    "                os.makedirs(new_dir)\n",
    "                with ZipFile(os.path.join(path, file), 'r') as zip_ref:\n",
    "                    zip_ref.extractall(new_dir)\n",
    "\n",
    "extract_zip_files(\"./../data/LAC_DATA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dirs = [d for d in os.listdir(\"./../data/LAC_DATA\") if not d.endswith(\".zip\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class eCR:\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "        self.tree = etree.parse(path)\n",
    "        self.root = self.tree.getroot()\n",
    "        self.ns = self.root.nsmap\n",
    "        self.ns['default'] = self.ns.pop(None)\n",
    "\n",
    "class RR(eCR):\n",
    "    def __init__(self, path):\n",
    "        super().__init__(path)\n",
    "\n",
    "class eICR(eCR):\n",
    "    def __init__(self, path):\n",
    "        super().__init__(path)\n",
    "    \n",
    "    def get_patient_id(self):\n",
    "        return self.root.find('.//default:patient/default:id', self.ns).attrib['extension']\n",
    "    \n",
    "    def get_patient_name(self):\n",
    "        given = self.root.find('.//default:patient/default:name/default:given', self.ns).text\n",
    "        family = self.root.find('.//default:patient/default:name/default:family', self.ns).text\n",
    "        return f\"{given} {family}\"\n",
    "    \n",
    "    def get_patient_dob(self):\n",
    "        return self.root.find('.//default:patient/default:birthTime', self.ns).attrib['value']\n",
    "    \n",
    "    def get_send_date(self):\n",
    "        time = self.root.find('.//default:effectiveTime', self.ns)\n",
    "        if time is not None:\n",
    "            return self._format_date_time(time.attrib.get('value'))\n",
    "        \n",
    "    def get_encounter_id(self):\n",
    "        id = self.root.find('.//default:encounter/default:id', self.ns)\n",
    "        if id is not None:\n",
    "            return id.attrib.get('extension')\n",
    "\n",
    "    def get_set_id(self):\n",
    "        id = self.root.find('.//default:setId', self.ns)\n",
    "        if id is not None:\n",
    "            return id.attrib.get('extension')\n",
    "\n",
    "    def get_ecr_version(self):\n",
    "        version = self.root.find('.//default:versionNumber', self.ns)\n",
    "        if version is not None:\n",
    "            return version.attrib.get('value') or version.text\n",
    "\n",
    "    def get_sections(self):\n",
    "        return self.root.findall('.//default:section', self.ns)\n",
    "    \n",
    "    def _format_date_time(self, date_time):\n",
    "        if date_time is not None:\n",
    "            return datetime.strptime(date_time, '%Y%m%d%H%M%S%z').isoformat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "section_name_counts = {}\n",
    "\n",
    "for dir in all_dirs:\n",
    "    # read in the CDA_eICR.xml file, get the sections, and print the section titles\n",
    "    file_path = Path(\"./../data/LAC_DATA/\" + dir + \"/CDA_eICR.xml\")\n",
    "    ecr = eICR(file_path)\n",
    "    sections = ecr.get_sections()\n",
    "    for section in sections:\n",
    "        section_name = section.find('.//default:title', ecr.ns).text\n",
    "        if section_name in section_name_counts:\n",
    "            section_name_counts[section_name] += 1\n",
    "        else:\n",
    "            section_name_counts[section_name] = 1\n",
    "\n",
    "print(f\"Found {len(section_name_counts)} unique section names\")\n",
    "for k,v in sorted(section_name_counts.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(k + \": \" + str(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "section_name_taxonomy = {\n",
    "    \"Allergy Information\": [],\n",
    "    \"Patient Information\": [],\n",
    "    \"Encounter Information\": [],\n",
    "    \"Provider Information\": [],\n",
    "    \"Clinical Information\": [],\n",
    "    \"Medication Information\": [],\n",
    "    \"Immunizations\": [],\n",
    "    \"Diagnoses\": [],\n",
    "    \"Reason for Visit\": [],\n",
    "    \"Care Plan\": [],\n",
    "    \"Social History\": [],\n",
    "    \"Family History\": [],\n",
    "    \"Problems\": [],\n",
    "    \"Notes\": [],\n",
    "    \"Other\": [],\n",
    "}\n",
    "\n",
    "for section_name in section_name_counts:\n",
    "    if \"encounter\" in section_name.lower():\n",
    "        section_name_taxonomy[\"Encounter Information\"].append(section_name)\n",
    "    elif \"allergy\" in section_name.lower() or \"allergies\" in section_name.lower():\n",
    "        section_name_taxonomy[\"Allergy Information\"].append(section_name)\n",
    "    elif \"provider\" in section_name.lower():\n",
    "        section_name_taxonomy[\"Provider Information\"].append(section_name)\n",
    "    elif \"clinical\" in section_name.lower():\n",
    "        section_name_taxonomy[\"Clinical Information\"].append(section_name)\n",
    "    elif \"medication\" in section_name.lower():\n",
    "        section_name_taxonomy[\"Medication Information\"].append(section_name)\n",
    "    elif \"care\" in section_name.lower() or \"plan\" in section_name.lower():\n",
    "        section_name_taxonomy[\"Care Plan\"].append(section_name)\n",
    "    elif \"social\" in section_name.lower():\n",
    "        section_name_taxonomy[\"Social History\"].append(section_name)\n",
    "    elif \"family\" in section_name.lower():\n",
    "        section_name_taxonomy[\"Family History\"].append(section_name)\n",
    "    elif \"problem\" in section_name.lower():\n",
    "        section_name_taxonomy[\"Problems\"].append(section_name)\n",
    "    elif \"diagnoses\" in section_name.lower() or \"diagnosis\" in section_name.lower():\n",
    "        section_name_taxonomy[\"Diagnoses\"].append(section_name)\n",
    "    elif \"reason\" in section_name.lower():\n",
    "        section_name_taxonomy[\"Reason for Visit\"].append(section_name)\n",
    "    elif \"immunization\" in section_name.lower():\n",
    "        section_name_taxonomy[\"Immunizations\"].append(section_name)\n",
    "    elif \"problem\" in section_name.lower():\n",
    "        section_name_taxonomy[\"Problems\"].append(section_name)\n",
    "    elif \"note\" in section_name.lower():\n",
    "        section_name_taxonomy[\"Notes\"].append(section_name)\n",
    "    elif \"patient\" in section_name.lower():\n",
    "        section_name_taxonomy[\"Patient Information\"].append(section_name)\n",
    "    else:\n",
    "        section_name_taxonomy[\"Other\"].append(section_name)\n",
    "\n",
    "for k,v in section_name_taxonomy.items():\n",
    "    print(f\"{k}: {len(v)}\")\n",
    "    for section in v:\n",
    "        print(f\"\\t{section}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above analysis shows how difficult it will be to parse eCR documents as the section names are not standardized. However, they are generally categorizable, which provides some options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Preprocessing\n",
    "# stop = set(stopwords.words('english'))\n",
    "# exclude = set(string.punctuation)\n",
    "# lemma = WordNetLemmatizer()\n",
    "\n",
    "# def clean(doc):\n",
    "#     stop_free = \" \".join([i for i in doc.lower().split() if i not in stop])\n",
    "#     punc_free = ''.join(ch for ch in stop_free if ch not in exclude)\n",
    "#     normalized = \" \".join(lemma.lemmatize(word) for word in punc_free.split())\n",
    "#     return normalized\n",
    "\n",
    "# section_names_clean = [clean(doc) for doc in section_name_counts]\n",
    "\n",
    "# # Convert the section names into a matrix of token counts\n",
    "# vectorizer = CountVectorizer()\n",
    "# section_names_term_matrix = vectorizer.fit_transform(section_names_clean)\n",
    "\n",
    "# # Train LDA model\n",
    "# lda = LatentDirichletAllocation(n_components=10, random_state=0)\n",
    "# lda.fit(section_names_term_matrix)\n",
    "\n",
    "# # Classify section names\n",
    "# section_names_topics = lda.transform(section_names_term_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# most_likely_topics = np.argmax(section_names_topics, axis=1)\n",
    "# topic_labels = [\"Topic\" + str(i) for i in range(lda.n_components)]\n",
    "# section_name_labels = [topic_labels[i] for i in most_likely_topics]\n",
    "# topics = {}\n",
    "# for section_name, label in zip(section_name_counts, section_name_labels):\n",
    "#     if label in topics:\n",
    "#         topics[label].append(section_name)\n",
    "#     else:\n",
    "#         topics[label] = [section_name]\n",
    "\n",
    "# for k,v in topics.items():\n",
    "#     print(f\"{k}: {len(v)}\")\n",
    "#     for section in v:\n",
    "#         print(f\"\\t{section}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecrs_by_patient = {}\n",
    "for dir in all_dirs:\n",
    "    file_path = Path(\"./../data/LAC_DATA/\" + dir + \"/CDA_eICR.xml\")\n",
    "    ecr = eICR(file_path)\n",
    "    patient_name = ecr.get_patient_name()\n",
    "    if patient_name in ecrs_by_patient:\n",
    "        ecrs_by_patient[patient_name].append(file_path)\n",
    "    else:\n",
    "        ecrs_by_patient[patient_name] = [file_path]\n",
    "\n",
    "for name, count in sorted(ecrs_by_patient.items(), key=lambda x: len(x[1]), reverse=True):\n",
    "    print(f\"{name}: {len(count)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_section_names(doc1, doc2):\n",
    "    ecr1 = eICR(doc1)\n",
    "    ecr2 = eICR(doc2)\n",
    "    sections1 = ecr1.get_sections()\n",
    "    sections2 = ecr2.get_sections()\n",
    "    section_names1 = [section.find('.//default:title', ecr1.ns).text for section in sections1]\n",
    "    section_names2 = [section.find('.//default:title', ecr2.ns).text for section in sections2]\n",
    "\n",
    "    return {\n",
    "        \"Both\": set(section_names1).intersection(set(section_names2)),\n",
    "        \"Doc 1 Only\": set(section_names1) - set(section_names2),\n",
    "        \"Doc 2 Only\": set(section_names2) - set(section_names1)\n",
    "    }\n",
    "\n",
    "compare_section_names(ecrs_by_patient['Peter Pan Epictest'][0], ecrs_by_patient['Peter Pan Epictest'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_cell_data(cell):\n",
    "    if cell.find('.//default:content', ecr.ns) is not None:\n",
    "        return cell.find('.//default:content', ecr.ns).text\n",
    "    else:\n",
    "        return cell.text\n",
    "\n",
    "def parse_section_content(section):\n",
    "    # extract table data from the section\n",
    "    \"\"\"\n",
    "    Example data\n",
    "    <section>\n",
    "        <templateId root=\"2.16.840.1.113883.10.20.22.2.10\"/>\n",
    "        <templateId extension=\"2014-06-09\" root=\"2.16.840.1.113883.10.20.22.2.10\"/>\n",
    "        <code code=\"18776-5\" codeSystem=\"2.16.840.1.113883.6.1\" codeSystemName=\"LOINC\" displayName=\"Plan of care note\"/>\n",
    "        <title>\n",
    "            Plan of Treatment\n",
    "        </title>\n",
    "        <text>\n",
    "            <table>\n",
    "                <caption>\n",
    "                    Pending Results\n",
    "                </caption>\n",
    "                <colgroup>\n",
    "                    <col width=\"25%\"/>\n",
    "                    <col width=\"15%\"/>\n",
    "                    <col width=\"10%\"/>\n",
    "                    <col span=\"2\" width=\"25%\"/>\n",
    "                </colgroup>\n",
    "                <thead>\n",
    "                    <tr>\n",
    "                        <th>Name</th>\n",
    "                        <th>Type</th>\n",
    "                        <th>Priority</th>\n",
    "                        <th>Associated Diagnoses</th>\n",
    "                        <th>Date/Time</th>\n",
    "                    </tr>\n",
    "                </thead>\n",
    "                <tbody>\n",
    "                    <tr ID=\"procedure9\">\n",
    "                        <td>\n",
    "                            <content ID=\"procedure9name\">\n",
    "                                Drugs Of Abuse Comprehensive Screen, Ur\n",
    "                            </content>\n",
    "                        </td>\n",
    "                        <td>Lab</td>\n",
    "                        <td>STAT</td>\n",
    "                        <td/><td>12/23/2022 11:13 AM PST</td>\n",
    "                    </tr>\n",
    "                </tbody>\n",
    "            </table>\n",
    "            <table>\n",
    "                <caption>Scheduled Orders</caption>\n",
    "                <colgroup>\n",
    "                    <col width=\"25%\"/>\n",
    "                    <col width=\"15%\"/>\n",
    "                    <col width=\"10%\"/>\n",
    "                    <col span=\"2\" width=\"25%\"/>\n",
    "                </colgroup>\n",
    "                <thead>\n",
    "                    <tr>\n",
    "                        <th>Name</th>\n",
    "                        <th>Type</th>\n",
    "                        <th>Priority</th>\n",
    "                        <th>Associated Diagnoses</th>\n",
    "                        <th>Order Schedule</th>\n",
    "                    </tr>\n",
    "                </thead>\n",
    "                <tbody>\n",
    "                    <tr ID=\"procedure10\">\n",
    "                        <td>\n",
    "                            <content ID=\"procedure10name\">\n",
    "                                Drugs Of Abuse Comprehensive Screen, Ur\n",
    "                            </content>\n",
    "                        </td>\n",
    "                        <td>Lab</td>\n",
    "                        <td>Routine</td>\n",
    "                        <td/>\n",
    "                        <td ID=\"procedure10schedule\">\n",
    "                            One Time for 1 Occurrences starting 12/23/22 until 12/23/22\n",
    "                        </td>\n",
    "                    </tr>\n",
    "                </tbody>\n",
    "            </table>\n",
    "    \"\"\"\n",
    "    table_data = []\n",
    "    tables = section.findall('.//default:table', ecr.ns)\n",
    "    \n",
    "    for table in tables:\n",
    "        header = []\n",
    "        header_row = table.find('.//default:thead/default:tr', ecr.ns)\n",
    "        if header_row is not None:\n",
    "            for cell in header_row.findall('.//default:th', ecr.ns):\n",
    "                header.append(cell.text)\n",
    "            table_data.append(header)\n",
    "        for row in table.findall('.//default:tbody/default:tr', ecr.ns):\n",
    "            row_data = []\n",
    "            for cell in row.findall('.//default:td', ecr.ns):\n",
    "                row_data.append(extract_cell_data(cell))\n",
    "            table_data.append(row_data)\n",
    "    return table_data\n",
    "\n",
    "\n",
    "def compare_section_content(doc1, doc2, section_name):\n",
    "    ecr1 = eICR(doc1)\n",
    "    ecr2 = eICR(doc2)\n",
    "    sections1 = ecr1.get_sections()\n",
    "    sections2 = ecr2.get_sections()\n",
    "    section1 = None\n",
    "    section2 = None\n",
    "    for section in sections1:\n",
    "        if section.find('.//default:title', ecr1.ns).text == section_name:\n",
    "            section1 = parse_section_content(section)\n",
    "            break\n",
    "    for section in sections2:\n",
    "        if section.find('.//default:title', ecr2.ns).text == section_name:\n",
    "            section2 = parse_section_content(section)\n",
    "            break\n",
    "    return {\"Doc 1\": section1, \"Doc 2\": section2}\n",
    "\n",
    "compare_section_content(ecrs_by_patient['Peter Pan Epictest'][0], ecrs_by_patient['Peter Pan Epictest'][1], \"Plan of Treatment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: update the code above to handle multiple tables, as well as account for when there is a `<content>` tag in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_section_content_by_doc(patient_name, section_names):\n",
    "    if not isinstance(section_names, list):\n",
    "        section_names = [section_names]\n",
    "        \n",
    "    section_content_by_doc = {}\n",
    "    for doc in ecrs_by_patient[patient_name]:\n",
    "        ecr = eICR(doc)\n",
    "        send_date = ecr.get_send_date()\n",
    "        sections = ecr.get_sections()\n",
    "        version_number = ecr.get_ecr_version()\n",
    "        encounter_id = ecr.get_encounter_id()\n",
    "        set_id = ecr.get_set_id()\n",
    "        for section in sections:\n",
    "            section_name = section.find('.//default:title', ecr.ns).text\n",
    "            if section_name in section_names:\n",
    "                section_content_by_doc[f\"{doc} - {send_date}\"] = parse_section_content(section)\n",
    "\n",
    "    for doc, content in section_content_by_doc.items():\n",
    "        print(f\"{doc} - {encounter_id}:{set_id}:{version_number}\")\n",
    "        for table in content:\n",
    "            print(table)\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_section_content_by_doc('Peter Pan Epictest', 'Plan of Treatment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_section_content_by_doc(\n",
    "    'Peter Pan Epictest', \n",
    "    ['Encounter Details', 'Encounters', 'Encounter', 'ENCOUNTERS']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encounter_statistics = {}\n",
    "\n",
    "for dir in all_dirs:\n",
    "    file_path = Path(\"./../data/LAC_DATA/\" + dir + \"/CDA_eICR.xml\")\n",
    "    ecr = eICR(file_path)\n",
    "    encounter_id = ecr.get_encounter_id()\n",
    "    set_id = ecr.get_set_id()\n",
    "    version_number = ecr.get_ecr_version()\n",
    "\n",
    "    if encounter_id in encounter_statistics:\n",
    "        encounter_statistics[encounter_id][\"file_paths\"].append(file_path)\n",
    "        encounter_statistics[encounter_id][\"set_ids\"].append(set_id)\n",
    "        encounter_statistics[encounter_id][\"version_numbers\"].append(version_number)\n",
    "    else:\n",
    "        encounter_statistics[encounter_id] = {\n",
    "            \"file_paths\": [file_path],\n",
    "            \"set_ids\": [set_id],\n",
    "            \"version_numbers\": [version_number]\n",
    "        }\n",
    "\n",
    "for encounter_id, data in encounter_statistics.items():\n",
    "    print(f\"{encounter_id}:\")\n",
    "    print(f\"\\tNumber of files: {len(data['file_paths'])}\")\n",
    "    print(f\"\\tNumber of unique set IDs: {len(set(data['set_ids']))}\")\n",
    "    print(f\"\\tNumber of unique version numbers: {len(set(data['version_numbers']))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "section_names_by_assigning_authority_name = {}\n",
    "for dir in all_dirs:\n",
    "    file_path = Path(\"./../data/LAC_DATA/\" + dir + \"/CDA_eICR.xml\")\n",
    "    ecr = eICR(file_path)\n",
    "    sections = ecr.get_sections()\n",
    "    assigning_authority_name = ecr.root.find('.//default:setId', ecr.ns)\n",
    "    \n",
    "    if assigning_authority_name is None:\n",
    "        continue\n",
    "    \n",
    "    assigning_authority_name = assigning_authority_name.attrib.get('assigningAuthorityName')\n",
    "    for section in sections:\n",
    "        section_name = section.find('.//default:title', ecr.ns).text\n",
    "        \n",
    "        if assigning_authority_name in section_names_by_assigning_authority_name:\n",
    "            section_names_by_assigning_authority_name[assigning_authority_name].append(section_name)\n",
    "        else:\n",
    "            section_names_by_assigning_authority_name[assigning_authority_name] = [section_name]\n",
    "\n",
    "for k,v in section_names_by_assigning_authority_name.items():\n",
    "    print(f\"{k}: {len(set(v))}\")\n",
    "    for section in set(v):\n",
    "        print(f\"\\t{section}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dir in all_dirs:\n",
    "    ecr_fpath = Path(\"./../data/LAC_DATA/\" + dir + \"/CDA_eICR.xml\")\n",
    "    new_ecr_fpath = str(ecr_fpath).replace(\".xml\", \"_formatted.xml\")\n",
    "    if not os.path.exists(new_ecr_fpath):\n",
    "        ecr = eICR(ecr_fpath)\n",
    "        formatted_xml = etree.tostring(ecr.tree, pretty_print=True).decode('utf-8')\n",
    "        with open(new_ecr_fpath, 'w') as f:\n",
    "            f.write(formatted_xml)\n",
    "    \n",
    "    rr_fpath = Path(\"./../data/LAC_DATA/\" + dir + \"/CDA_RR.xml\")\n",
    "    new_rr_fpath = str(rr_fpath).replace(\".xml\", \"_formatted.xml\")\n",
    "    if not os.path.exists(new_rr_fpath):\n",
    "        rr = RR(rr_fpath)\n",
    "        formatted_xml = etree.tostring(rr.tree, pretty_print=True).decode('utf-8')\n",
    "        with open(new_rr_fpath, 'w') as f:\n",
    "            f.write(formatted_xml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_diff_heatmap(patient_name):\n",
    "    ecrs = [str(fpath).replace(\".xml\", \"_formatted.xml\") for fpath in ecrs_by_patient[patient_name]]\n",
    "    n = len(ecrs)\n",
    "    differences = [[0] * n for _ in range(n)]\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            diff = main.diff_files(ecrs[i], ecrs[j])\n",
    "            differences[i][j] = len(diff)\n",
    "            differences[j][i] = len(diff)\n",
    "    sns.heatmap(differences, cmap='coolwarm')\n",
    "    plt.xticks(ticks=[i + 0.5 for i in range(n)], labels=range(1, n+1))\n",
    "    plt.yticks(ticks=[i + 0.5 for i in range(n)], labels=range(1, n+1))\n",
    "    plt.xlabel('eCR Number')\n",
    "    plt.ylabel('eCR Number')\n",
    "    plt.show()\n",
    "\n",
    "#generate_diff_heatmap('Peter Pan Epictest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecrs_by_patient.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract all of the text from any section in the eICR that mentions \"Notes\" in the title\n",
    "def extract_notes_text(patient_name):\n",
    "    notes_text_count = {}\n",
    "    for doc in ecrs_by_patient[patient_name]:\n",
    "        ecr = eICR(doc)\n",
    "        sections = ecr.get_sections()\n",
    "        for section in sections:\n",
    "            section_name = section.find('.//default:title', ecr.ns).text\n",
    "            if \"note\" in section_name.lower():\n",
    "                print(f\"Found a notes section: {section_name}\")\n",
    "                notes_content = section.find('.//default:text/default:content', ecr.ns)\n",
    "                text = notes_content.text.replace('\\n', '').strip() if notes_content is not None else None\n",
    "                if text is not None:\n",
    "                    if section_name in notes_text_count:\n",
    "                        if text in notes_text_count[section_name]:\n",
    "                            notes_text_count[section_name][text] += 1\n",
    "                        else:\n",
    "                            notes_text_count[section_name][text] = 1\n",
    "                    else:\n",
    "                        notes_text_count[section_name] = {text: 1}\n",
    "    return notes_text_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for patient in ecrs_by_patient:\n",
    "    notes_text = extract_notes_text(patient)\n",
    "    if notes_text:\n",
    "        print(f\"{patient}:\")\n",
    "        for section_name in notes_text:\n",
    "            print(f\"\\t{section_name}:\")\n",
    "            for note, count in notes_text[section_name].items():\n",
    "                print(f\"\\t\\t{note}: {count}\")\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each notes section, extract the raw XML starting with the <section> tag and ending with the </section> tag\n",
    "def extract_notes_xml(patient_name):\n",
    "    notes_xml = []\n",
    "    for doc in ecrs_by_patient[patient_name]:\n",
    "        ecr = eICR(doc)\n",
    "        sections = ecr.get_sections()\n",
    "        for section in sections:\n",
    "            section_name = section.find('.//default:title', ecr.ns).text\n",
    "            if \"note\" in section_name.lower():\n",
    "                xml = etree.tostring(section,  pretty_print=True).decode('utf-8')\n",
    "                notes_xml.append(xml)\n",
    "    return notes_xml\n",
    "\n",
    "# print each notes section in formatted XML\n",
    "def print_notes_xml(patient_name):\n",
    "    notes_xml = extract_notes_xml(patient_name)\n",
    "    for xml in notes_xml:\n",
    "        print(xml)\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_notes_xml('Adam Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many conditions are represented in the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. How many repeated results are we getting with the same day/time across different eICRs?\n",
    "2. What's the minimum definition of a \"document\"?\n",
    "3. What's the minimum definition of a \"patient record\"?\n",
    "4. According to the definitions in 2. and 3., how many duplicates do we have?\n",
    "\n",
    "Things to consider adding to the Research Plan (not exact quotes or findings):\n",
    "\"Based on the LAC data, we found that 20% of documents were duplicated. We hypothesize that this will generalize across other STLTs as well.\"\n",
    "\"Hypothesis: The definition of a document is <insert definition>. We are looking for these fields: <insert field>\"\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
